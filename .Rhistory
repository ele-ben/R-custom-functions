#facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
# Chunk 4
for (i in 1:nSim){
data.grp1 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
data.grp1[,2] <- data.grp1[,2] + dav.task
data.grp1[,3] <- data.grp1[,3] + dav.resp
data.grp1[,4] <- data.grp1[,4] + dav.resp + dav.task
data.grp1[,5] <- data.grp1[,5] + dav.context
data.grp1[,6] <- data.grp1[,6] + dav.context + dav.task
data.grp1[,7] <- data.grp1[,7] + dav.context + dav.resp
data.grp1[,8] <- data.grp1[,8] + dav.context + dav.resp + dav.task
# data.grp2 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# data.grp2[,2] <- data.grp2[,2] + dav.task + dav.group
# data.grp2[,3] <- data.grp2[,4] + dav.resp + dav.group
# data.grp2[,4] <- data.grp2[,4] + dav.resp + dav.task + dav.group
# data.grp2[,5] <- data.grp2[,5] + dav.context + dav.group
# data.grp2[,6] <- data.grp2[,6] + dav.context + dav.task + dav.group
# data.grp2[,7] <- data.grp2[,7] + dav.context + dav.resp + dav.group
# data.grp2[,8] <- data.grp2[,8] + dav.context + dav.resp + dav.task + dav.group
# dv <- Reshape(cbind(data.grp1, data.grp2), N*dim(data.grp1)[2]*2, 1)
# data <- rbind(facs, facs2)
# data$dv <- dv
# data$grp <- c(rep("1", nrow(data)/2), rep("2", nrow(data)/2))
dv <- Reshape(data.grp1, N*dim(data.grp1)[2], 1)
data <- facs
data$dv <- dv
data$subj <- as.factor(data$subj)
#data$grp <- as.factor(data$grp)
data$task <- as.factor(data$task)
data$resp <- as.factor(data$resp)
data$cont <- as.factor(data$cont)
#mod <- lme(dv ~ task*resp*cont + grp, random = ~ 1 | subj, data)
mod <- lme(dv ~ task*resp*cont, random = ~ 1 | subj, data)
test <- summary(mod)$tTable
p.task[i] <- test["task1", "p-value"]
p.resp[i] <- test["resp1", "p-value"]
p.context[i] <- test["cont1", "p-value"]
p.resp.task[i] <- test["task1:resp1", "p-value"] # 2 way
p.resp.task.context[i] <- test["task1:resp1:cont1", "p-value"] #3-way interaction
#p.group[i] <- test["grp2", "p-value"] #interaction
}
test
data
mean(data.grp2[,8])
mean(data.grp1[,8])
mean(data.grp1[,7])
mean(data.grp1[,6])
# results are as predicted when the following are simultaneously significant:
# task relation x response relation
# task relation x response relation x context relation
supportH1 <- sum(p.task < alpha & p.resp < alpha &
p.resp.task < alpha & p.resp.task.context < alpha)/nSim
cat("Power of the test is ",supportH1,"\n")
sign.resp.task <- sum(p.resp.task < alpha)/nSim
cat("Significance resp*task inter ",sign.resp.task,"\n")
sign.resp.task.context <- sum(p.resp.task.context < alpha)/nSim
cat("Significance resp*task*context inter ",sign.resp.task.context ,"\n")
#sign.grp <- sum(p.group < alpha)/nSim
#cat("Significance interaction ",sign.grp,"\n")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
if(!require(pacman)) install.packages("pacman")
pacman::p_load("MASS", "ez", "pracma", "lme4", "nlme")
# Chunk 2
Eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
# Chunk 3
#Sample size in each group
N = 100
r = 0.5
d.resp = 0.4
d.task = 0.4
d.context = 0.2
#d.group = 0.2 #the between group manipualtion has a further effect
# calculate a different effect size useful to data generating process
dav.resp = d.resp*sqrt(2*(1-r)) #dav=dz when repeated measures have rho=.5
dav.task = d.task*sqrt(2*(1-r))
dav.context = d.context*sqrt(2*(1-r))
#dav.group = d.group*sqrt(2*(1-r))
alpha = .05
nSim = 100
# prepare vectors to store p-values
p.resp<- numeric(nSim)
p.task <- numeric(nSim)
p.context <- numeric(nSim)
p.resp.task <- numeric(nSim)
p.resp.task.context <- numeric(nSim)
#p.group <- numeric(nSim)
rho <- matrix(r, 8, 8)
diag(rho) <- 1
pps <- c(1:N)
#pps2 <- c(1:N)+N
facs <- expand.grid(subj = pps, task = c(0,1), resp = c(0,1), cont = c(0,1))
#facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
# Chunk 4
for (i in 1:nSim){
data.grp1 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
data.grp1[,2] <- data.grp1[,2] + dav.task
data.grp1[,3] <- data.grp1[,3] + dav.resp
data.grp1[,4] <- data.grp1[,4] + dav.resp + dav.task
data.grp1[,5] <- data.grp1[,5] + dav.context
data.grp1[,6] <- data.grp1[,6] + dav.context + dav.task
data.grp1[,7] <- data.grp1[,7] + dav.context + dav.resp
data.grp1[,8] <- data.grp1[,8] + dav.context + dav.resp + dav.task
# data.grp2 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# data.grp2[,2] <- data.grp2[,2] + dav.task + dav.group
# data.grp2[,3] <- data.grp2[,4] + dav.resp + dav.group
# data.grp2[,4] <- data.grp2[,4] + dav.resp + dav.task + dav.group
# data.grp2[,5] <- data.grp2[,5] + dav.context + dav.group
# data.grp2[,6] <- data.grp2[,6] + dav.context + dav.task + dav.group
# data.grp2[,7] <- data.grp2[,7] + dav.context + dav.resp + dav.group
# data.grp2[,8] <- data.grp2[,8] + dav.context + dav.resp + dav.task + dav.group
# dv <- Reshape(cbind(data.grp1, data.grp2), N*dim(data.grp1)[2]*2, 1)
# data <- rbind(facs, facs2)
# data$dv <- dv
# data$grp <- c(rep("1", nrow(data)/2), rep("2", nrow(data)/2))
dv <- Reshape(data.grp1, N*dim(data.grp1)[2], 1)
data <- facs
data$dv <- dv
data$subj <- as.factor(data$subj)
#data$grp <- as.factor(data$grp)
data$task <- as.factor(data$task)
data$resp <- as.factor(data$resp)
data$cont <- as.factor(data$cont)
#mod <- lme(dv ~ task*resp*cont + grp, random = ~ 1 | subj, data)
mod <- lme(dv ~ task*resp*cont, random = ~ 1 | subj, data)
test <- summary(mod)$tTable
p.task[i] <- test["task1", "p-value"]
p.resp[i] <- test["resp1", "p-value"]
p.context[i] <- test["cont1", "p-value"]
p.resp.task[i] <- test["task1:resp1", "p-value"] # 2 way
p.resp.task.context[i] <- test["task1:resp1:cont1", "p-value"] #3-way interaction
#p.group[i] <- test["grp2", "p-value"] #interaction
}
# results are as predicted when the following are simultaneously significant:
# task relation x response relation
# task relation x response relation x context relation
supportH1 <- sum(p.task < alpha & p.resp < alpha &
p.resp.task < alpha & p.resp.task.context < alpha)/nSim
cat("Power of the test is ",supportH1,"\n")
sign.resp.task <- sum(p.resp.task < alpha)/nSim
cat("Significance resp*task inter ",sign.resp.task,"\n")
sign.resp.task.context <- sum(p.resp.task.context < alpha)/nSim
cat("Significance resp*task*context inter ",sign.resp.task.context ,"\n")
#sign.grp <- sum(p.group < alpha)/nSim
#cat("Significance interaction ",sign.grp,"\n")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
if(!require(pacman)) install.packages("pacman")
pacman::p_load("MASS", "ez", "pracma", "lme4", "nlme")
# Chunk 2
Eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
# Chunk 3
#Sample size (in each group)
N = 32
r = 0.5
#list of effect size. I just used Brysbaert recommedations, then I will use more informed values, but for now it should work
d.resp = 0.4
d.task = 0.4
d.context = 0.2
#d.group = 0.2 #the between group manipualtion has a further effect
# calculate a different effect size useful to data generating process
dav.resp = d.resp*sqrt(2*(1-r)) #dav=dz when repeated measures have rho=.5
dav.task = d.task*sqrt(2*(1-r))
dav.context = d.context*sqrt(2*(1-r))
#dav.group = d.group*sqrt(2*(1-r))
alpha = .05
nSim = 5000
# prepare vectors to store p-values
p.resp<- numeric(nSim)
p.task <- numeric(nSim)
p.context <- numeric(nSim)
p.resp.task <- numeric(nSim)
p.resp.task.context <- numeric(nSim)
#p.group <- numeric(nSim)
# var covar matrix of the within-subjs variable. There are 8 variables because all the possible combiantions are considered
rho <- matrix(r, 8, 8)
#set the diag to 1, to get a proper var covar matrix
diag(rho) <- 1
# just a vector with participants numbers
pps <- c(1:N)
#pps2 <- c(1:N)+N
# all the possible combinations of participants and conditions
facs <- expand.grid(subj = pps, task = c(0,1), resp = c(0,1), cont = c(0,1))
#facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
# Chunk 4
for (i in 1:nSim){
# generate the data from a 8-variate normal distribution, where variables have  correlation = r
data.grp1 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# add the effect size on the basis of the specific crossing of conditions
# the criterion to assign a ceratin effect to a certain column is the order of the combinations of the varibales in facs variable
data.grp1[,2] <- data.grp1[,2] + dav.task #when the column in facs has task=1, I add the effect, same for the following lines
data.grp1[,3] <- data.grp1[,3] + dav.resp
data.grp1[,4] <- data.grp1[,4] + dav.resp + dav.task
data.grp1[,5] <- data.grp1[,5] + dav.context
data.grp1[,6] <- data.grp1[,6] + dav.context + dav.task
data.grp1[,7] <- data.grp1[,7] + dav.context + dav.resp
data.grp1[,8] <- data.grp1[,8] + dav.context + dav.resp + dav.task
# data.grp2 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# data.grp2[,2] <- data.grp2[,2] + dav.task + dav.group
# data.grp2[,3] <- data.grp2[,4] + dav.resp + dav.group
# data.grp2[,4] <- data.grp2[,4] + dav.resp + dav.task + dav.group
# data.grp2[,5] <- data.grp2[,5] + dav.context + dav.group
# data.grp2[,6] <- data.grp2[,6] + dav.context + dav.task + dav.group
# data.grp2[,7] <- data.grp2[,7] + dav.context + dav.resp + dav.group
# data.grp2[,8] <- data.grp2[,8] + dav.context + dav.resp + dav.task + dav.group
# dv <- Reshape(cbind(data.grp1, data.grp2), N*dim(data.grp1)[2]*2, 1)
# data <- rbind(facs, facs2)
# data$dv <- dv
# data$grp <- c(rep("1", nrow(data)/2), rep("2", nrow(data)/2))
dv <- Reshape(data.grp1, N*dim(data.grp1)[2], 1) # the simulated data are reshaped into a column vector
data <- facs #the data frame is created adding the subjects and variables columns and then the dv
data$dv <- dv
# model part
data$subj <- as.factor(data$subj)
#data$grp <- as.factor(data$grp)
data$task <- as.factor(data$task)
data$resp <- as.factor(data$resp)
data$cont <- as.factor(data$cont)
# a multilevel model with random intercept (but not slope) is estimated
#mod <- lme(dv ~ task*resp*cont + grp, random = ~ 1 | subj, data)
mod <- lme(dv ~ task*resp*cont, random = ~ 1 | subj, data)
test <- summary(mod)$tTable # I save the table with coefficients and pvalues
# just store the p-values of interest in each loop
p.task[i] <- test["task1", "p-value"]
p.resp[i] <- test["resp1", "p-value"]
p.context[i] <- test["cont1", "p-value"]
p.resp.task[i] <- test["task1:resp1", "p-value"] # 2 way
p.resp.task.context[i] <- test["task1:resp1:cont1", "p-value"] #3-way interaction
#p.group[i] <- test["grp2", "p-value"] #interaction
}
# results are as predicted when the following are simultaneously significant:
# task relation x response relation
# task relation x response relation x context relation
supportH1 <- sum(p.task < alpha & p.resp < alpha &
p.resp.task < alpha & p.resp.task.context < alpha)/nSim
cat("Power of the test is ",supportH1,"\n")
sign.resp.task <- sum(p.resp.task < alpha)/nSim
cat("Significance resp*task inter ",sign.resp.task,"\n")
sign.resp.task.context <- sum(p.resp.task.context < alpha)/nSim
cat("Significance resp*task*context inter ",sign.resp.task.context ,"\n")
#sign.grp <- sum(p.group < alpha)/nSim
#cat("Significance interaction ",sign.grp,"\n")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
if(!require(pacman)) install.packages("pacman")
pacman::p_load("MASS", "ez", "pracma", "lme4", "nlme")
# Chunk 2
Eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
# Chunk 3
#Sample size (in each group)
N = 32
r = 0.5
#list of effect size. I just used Brysbaert recommedations, then I will use more informed values, but for now it should work
d.resp = 0.4
d.task = 1
d.context = 0.4
#d.group = 0.2 #the between group manipualtion has a further effect
# calculate a different effect size useful to data generating process
dav.resp = d.resp*sqrt(2*(1-r)) #dav=dz when repeated measures have rho=.5
dav.task = d.task*sqrt(2*(1-r))
dav.context = d.context*sqrt(2*(1-r))
#dav.group = d.group*sqrt(2*(1-r))
alpha = .05
nSim = 5000
# prepare vectors to store p-values
p.resp<- numeric(nSim)
p.task <- numeric(nSim)
p.context <- numeric(nSim)
p.resp.task <- numeric(nSim)
p.resp.task.context <- numeric(nSim)
#p.group <- numeric(nSim)
# var covar matrix of the within-subjs variable. There are 8 variables because all the possible combiantions are considered
rho <- matrix(r, 8, 8)
#set the diag to 1, to get a proper var covar matrix
diag(rho) <- 1
# just a vector with participants numbers
pps <- c(1:N)
#pps2 <- c(1:N)+N
# all the possible combinations of participants and conditions
facs <- expand.grid(subj = pps, task = c(0,1), resp = c(0,1), cont = c(0,1))
#facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
# Chunk 4
for (i in 1:nSim){
# generate the data from a 8-variate normal distribution, where variables have  correlation = r
data.grp1 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# add the effect size on the basis of the specific crossing of conditions
# the criterion to assign a ceratin effect to a certain column is the order of the combinations of the varibales in facs variable
data.grp1[,2] <- data.grp1[,2] + dav.task #when the column in facs has task=1, I add the effect, same for the following lines
data.grp1[,3] <- data.grp1[,3] + dav.resp
data.grp1[,4] <- data.grp1[,4] + dav.resp + dav.task
data.grp1[,5] <- data.grp1[,5] + dav.context
data.grp1[,6] <- data.grp1[,6] + dav.context + dav.task
data.grp1[,7] <- data.grp1[,7] + dav.context + dav.resp
data.grp1[,8] <- data.grp1[,8] + dav.context + dav.resp + dav.task
# data.grp2 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# data.grp2[,2] <- data.grp2[,2] + dav.task + dav.group
# data.grp2[,3] <- data.grp2[,4] + dav.resp + dav.group
# data.grp2[,4] <- data.grp2[,4] + dav.resp + dav.task + dav.group
# data.grp2[,5] <- data.grp2[,5] + dav.context + dav.group
# data.grp2[,6] <- data.grp2[,6] + dav.context + dav.task + dav.group
# data.grp2[,7] <- data.grp2[,7] + dav.context + dav.resp + dav.group
# data.grp2[,8] <- data.grp2[,8] + dav.context + dav.resp + dav.task + dav.group
# dv <- Reshape(cbind(data.grp1, data.grp2), N*dim(data.grp1)[2]*2, 1)
# data <- rbind(facs, facs2)
# data$dv <- dv
# data$grp <- c(rep("1", nrow(data)/2), rep("2", nrow(data)/2))
dv <- Reshape(data.grp1, N*dim(data.grp1)[2], 1) # the simulated data are reshaped into a column vector
data <- facs #the data frame is created adding the subjects and variables columns and then the dv
data$dv <- dv
# model part
data$subj <- as.factor(data$subj)
#data$grp <- as.factor(data$grp)
data$task <- as.factor(data$task)
data$resp <- as.factor(data$resp)
data$cont <- as.factor(data$cont)
# a multilevel model with random intercept (but not slope) is estimated
#mod <- lme(dv ~ task*resp*cont + grp, random = ~ 1 | subj, data)
mod <- lme(dv ~ task*resp*cont, random = ~ 1 | subj, data)
test <- summary(mod)$tTable # I save the table with coefficients and pvalues
# just store the p-values of interest in each loop
p.task[i] <- test["task1", "p-value"]
p.resp[i] <- test["resp1", "p-value"]
p.context[i] <- test["cont1", "p-value"]
p.resp.task[i] <- test["task1:resp1", "p-value"] # 2 way
p.resp.task.context[i] <- test["task1:resp1:cont1", "p-value"] #3-way interaction
#p.group[i] <- test["grp2", "p-value"] #interaction
}
# results are as predicted when the following are simultaneously significant:
# task relation x response relation
# task relation x response relation x context relation
supportH1 <- sum(p.task < alpha & p.resp < alpha &
p.resp.task < alpha & p.resp.task.context < alpha)/nSim
cat("Power of the test is ",supportH1,"\n")
# what I get: Power of the test is  0.0074
sign.resp.task <- sum(p.resp.task < alpha)/nSim
cat("Significance resp*task inter ",sign.resp.task,"\n")
# what I get: Significance resp*task inter  0.053
sign.resp.task.context <- sum(p.resp.task.context < alpha)/nSim
cat("Significance resp*task*context inter ",sign.resp.task.context ,"\n")
# what I get: Significance resp*task*context inter  0.0486
#sign.grp <- sum(p.group < alpha)/nSim
#cat("Significance interaction ",sign.grp,"\n")
eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
eta_to_dz(0.78, "within")
eta_to_dz(0.34, "within")
eta_to_dz(0.31, "within")
sqrt(0.31/(1-0.31))
eta_to_dz(0.91, "within")
eta_to_dz(0.18, "within")
eta_to_dz(0.79, "within")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
if(!require(pacman)) install.packages("pacman")
pacman::p_load("MASS", "ez", "pracma", "lme4", "nlme")
# Chunk 2
eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
# Chunk 3
#Sample size (in each group)
N = 32
r = 0.5
#list of effect size. I just used Brysbaert recommedations, then I will use more informed values, but for now it should work
d.resp = 0.4
d.task = 1
d.context = 0.4
#d.group = 0.2 #the between group manipualtion has a further effect
# calculate a different effect size useful to data generating process
dav.resp = d.resp*sqrt(2*(1-r)) #dav=dz when repeated measures have rho=.5
dav.task = d.task*sqrt(2*(1-r))
dav.context = d.context*sqrt(2*(1-r))
#dav.group = d.group*sqrt(2*(1-r))
alpha = .05
nSim = 1000
# prepare vectors to store p-values
p.resp<- numeric(nSim)
p.task <- numeric(nSim)
p.context <- numeric(nSim)
p.resp.task <- numeric(nSim)
p.resp.task.context <- numeric(nSim)
#p.group <- numeric(nSim)
# var covar matrix of the within-subjs variable. There are 8 variables because all the possible combiantions are considered
rho <- matrix(r, 8, 8)
#set the diag to 1, to get a proper var covar matrix
diag(rho) <- 1
# just a vector with participants numbers
pps <- c(1:N)
#pps2 <- c(1:N)+N
# all the possible combinations of participants and conditions
facs <- expand.grid(subj = pps, task = c(0,1), resp = c(0,1), cont = c(0,1))
#facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
# Chunk 4
for (i in 1:nSim){
# generate the data from a 8-variate normal distribution, where variables have  correlation = r
data.grp1 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# add the effect size on the basis of the specific crossing of conditions
# the criterion to assign a ceratin effect to a certain column is the order of the combinations of the varibales in facs variable
data.grp1[,2] <- data.grp1[,2] + dav.task #when the column in facs has task=1, I add the effect, same for the following lines
data.grp1[,3] <- data.grp1[,3] + dav.resp
data.grp1[,4] <- data.grp1[,4] + 0.5
data.grp1[,5] <- data.grp1[,5] + 0.2
data.grp1[,6] <- data.grp1[,6] + 0.3
data.grp1[,7] <- data.grp1[,7] + 0.3 + 0.1
data.grp1[,8] <- data.grp1[,8] +  0.3 + 0.5
# data.grp2 <- mvrnorm(n = N, mu = rep(0, 8), Sigma = rho)
# data.grp2[,2] <- data.grp2[,2] + dav.task + dav.group
# data.grp2[,3] <- data.grp2[,4] + dav.resp + dav.group
# data.grp2[,4] <- data.grp2[,4] + dav.resp + dav.task + dav.group
# data.grp2[,5] <- data.grp2[,5] + dav.context + dav.group
# data.grp2[,6] <- data.grp2[,6] + dav.context + dav.task + dav.group
# data.grp2[,7] <- data.grp2[,7] + dav.context + dav.resp + dav.group
# data.grp2[,8] <- data.grp2[,8] + dav.context + dav.resp + dav.task + dav.group
# dv <- Reshape(cbind(data.grp1, data.grp2), N*dim(data.grp1)[2]*2, 1)
# data <- rbind(facs, facs2)
# data$dv <- dv
# data$grp <- c(rep("1", nrow(data)/2), rep("2", nrow(data)/2))
dv <- Reshape(data.grp1, N*dim(data.grp1)[2], 1) # the simulated data are reshaped into a column vector
data <- facs #the data frame is created adding the subjects and variables columns and then the dv
data$dv <- dv
# model part
data$subj <- as.factor(data$subj)
#data$grp <- as.factor(data$grp)
data$task <- as.factor(data$task)
data$resp <- as.factor(data$resp)
data$cont <- as.factor(data$cont)
# a multilevel model with random intercept (but not slope) is estimated
#mod <- lme(dv ~ task*resp*cont + grp, random = ~ 1 | subj, data)
mod <- lme(dv ~ task*resp*cont, random = ~ 1 | subj, data)
test <- summary(mod)$tTable # I save the table with coefficients and pvalues
# just store the p-values of interest in each loop
p.task[i] <- test["task1", "p-value"]
p.resp[i] <- test["resp1", "p-value"]
p.context[i] <- test["cont1", "p-value"]
p.resp.task[i] <- test["task1:resp1", "p-value"] # 2 way
p.resp.task.context[i] <- test["task1:resp1:cont1", "p-value"] #3-way interaction
#p.group[i] <- test["grp2", "p-value"] #interaction
}
# results are as predicted when the following are simultaneously significant:
# task relation x response relation
# task relation x response relation x context relation
supportH1 <- sum(p.task < alpha & p.resp < alpha &
p.resp.task < alpha & p.resp.task.context < alpha)/nSim
cat("Power of the test is ",supportH1,"\n")
# what I get: Power of the test is  0.0074
sign.resp.task <- sum(p.resp.task < alpha)/nSim
cat("Significance resp*task inter ",sign.resp.task,"\n")
# what I get: Significance resp*task inter  0.053
sign.resp.task.context <- sum(p.resp.task.context < alpha)/nSim
cat("Significance resp*task*context inter ",sign.resp.task.context ,"\n")
# what I get: Significance resp*task*context inter  0.0486
#sign.grp <- sum(p.group < alpha)/nSim
#cat("Significance interaction ",sign.grp,"\n")
knitr::opts_chunk$set(echo = TRUE)
if(!require(pacman)) install.packages("pacman")
pacman::p_load("MASS", "ez", "pracma", "lme4", "nlme")
# not useful for this script particularly
eta_to_dz = function (PartEtaSq, design) {
if (design == "within"){fac = 1}
else {fac = 2}
dz = (sqrt(PartEtaSq/(1-PartEtaSq)))*fac
dz
}
#Sample size in each group
N = 5
r = 0.5
d.resp = 0.4
d.task = 0.4
d.context = 0.2
d.group = 0.2 #the between group manipualtion has a further effect
# calculate a different effect size useful to data generating process
dav.resp = d.resp*sqrt(2*(1-r)) #dav=dz when repeated measures have rho=.5
dav.task = d.task*sqrt(2*(1-r))
dav.context = d.context*sqrt(2*(1-r))
dav.group = d.group*sqrt(2*(1-r))
alpha = .05
nSim = 100
# prepare vectors to store p-values
p.resp <- numeric(nSim)
p.task <- numeric(nSim)
p.context <- numeric(nSim)
p.resp.task <- numeric(nSim)
p.resp.task.context <- numeric(nSim)
p.group <- numeric(nSim)
rho <- matrix(r, 8, 8)
diag(rho) <- 1
pps <- c(1:N)
pps2 <- c(1:N)+N
facs <- expand.grid(subj = pps, task = c(0,1), resp = c(0,1), cont = c(0,1))
facs2 <- expand.grid(subj = pps2, task = c(0,1), resp = c(0,1), cont = c(0,1))
